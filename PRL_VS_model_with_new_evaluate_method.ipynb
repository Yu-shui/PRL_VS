{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch as T\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.distributions import Bernoulli\n",
    "import h5py\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "from utils import *\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"Agg\")\n",
    "plt.rcParams['figure.figsize'] = (8.0, 4.0)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "from scipy.stats import rankdata\n",
    "import sys\n",
    "import hdf5storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Visual_Feature_Dim = 1024\n",
    "Global_Seq_Len = 20 #全局帧列的长度\n",
    "Local_Seq_Len = 20 #关键帧列的长度\n",
    "\n",
    "DATASET_NAME = 'summe'\n",
    "SAVE_DIR = 'resualt/20/' # path to save output (default: log/)\n",
    "RESUME = True\n",
    "LOAD_DIR = 'resualt/20/model_epoch14_0.39060460573767825_summe.pth.tar'\n",
    "METRIC = DATASET_NAME # evaluation metric ['tvsum', 'summe'])\n",
    "NUM_LAYERS = 1 # number of RNN layers (default: 1)\n",
    "START_EPOCH = 0\n",
    "epis = 0\n",
    "max_epis = 1\n",
    "BETA = 0.01  #default 0.1\n",
    "SEGMENT_LEN = 50 #fiveunits\n",
    "NUM_STEPS = 5\n",
    "Switch_Iteration = 10\n",
    "BATCH_SIZE = 1\n",
    "LR = 1e-05 # learning rate (default: 1e-05)\n",
    "WEIGHT_DECAY = 1e-05 # weight decay rate (default: 1e-05)\n",
    "MAX_EPOCH = 300 # maximum epoch for training (default: 60)\n",
    "STEP_SIZE = 30 # how many steps to decay learning rate (default: 30)\n",
    "\n",
    "\n",
    "\n",
    "DATASET = 'datasets/eccv16_dataset_' + DATASET_NAME + '_google_pool5.h5' \n",
    "SPLIT = 'datasets/' + DATASET_NAME + '_splits.json' # path to split file (required)\n",
    "SPLIT_ID = 0 # split index (default: 0)\n",
    "GAMMA = 0.1 # learning rate decay (default: 0.1)\n",
    "# Model options\n",
    "INPUT_DIM = 1024 # input dimension (default: 1024)\n",
    "HIDDEN_DIM = 256 # hidden unit dimension of DSN (default: 256)\n",
    "RNN_CELL = 'lstm' # RNN cell type (default: lstm)\n",
    "SEED = 1 # random seed (default: 1)\n",
    "GPU = '0' # which gpu devices to use (default: 0)\n",
    "USE_CPU = False # use cpu device\n",
    "EVALUATE = False # whether to do evaluation only\n",
    "TEST = False # whether to do evaluation only\n",
    "VERBOSE = True # whether to show detailed test results\n",
    "SAVE_RESULTS = True # whether to save output results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalized_columns_initializer(weights, std=1.0):\n",
    "    out = torch.randn(weights.size())\n",
    "    out *= std / torch.sqrt(out.pow(2).sum(1, keepdim=True).expand_as(out))\n",
    "    return out\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, mean=0, std=0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "    elif classname.find('Linear') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json(fpath):\n",
    "    with open(fpath, 'r') as f:\n",
    "        obj = json.load(f)\n",
    "    return obj\n",
    "\n",
    "def write_json(splits, save_path):\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.mkdir(os.path.dirname(save_path))\n",
    "\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(splits, f, indent=4, separators=(', ', ': '))\n",
    "        \n",
    "def save_checkpoint(state, fpath='checkpoint.pth.tar'):\n",
    "    if not os.path.exists(os.path.dirname(fpath)):\n",
    "        os.mkdir(os.path.dirname(fpath))\n",
    "\n",
    "    torch.save(state, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_ten_frame(N):\n",
    "    idx = []\n",
    "    ten_unit  = int(N / float(11))\n",
    "    for i in range(10):\n",
    "        idx.append(int(np.floor((i + 1) * ten_unit)))\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_inputs(values, weights, n_items, capacity):\n",
    "    # check variable type\n",
    "    assert(isinstance(values,list))\n",
    "    assert(isinstance(weights,list))\n",
    "    assert(isinstance(n_items,int))\n",
    "    assert(isinstance(capacity,int))\n",
    "    # check value type\n",
    "    assert(all(isinstance(val,int) or isinstance(val,float) for val in values))\n",
    "    assert(all(isinstance(val,int) for val in weights))\n",
    "    # check validity of value\n",
    "    assert(all(val >= 0 for val in weights))\n",
    "    assert(n_items > 0)\n",
    "    assert(capacity > 0)\n",
    "    \n",
    "def knapsack_dp(values,weights,n_items,capacity,return_all = False):\n",
    "    check_inputs(values,weights,n_items,capacity)\n",
    "\n",
    "    table = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
    "    keep = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
    "\n",
    "    for i in range(1,n_items+1):\n",
    "        for w in range(0,capacity+1):\n",
    "            wi = weights[i-1] # weight of current item\n",
    "            vi = values[i-1] # value of current item\n",
    "            if (wi <= w) and (vi + table[i-1,w-wi] > table[i-1,w]):\n",
    "                table[i,w] = vi + table[i-1,w-wi]\n",
    "                keep[i,w] = 1\n",
    "            else:\n",
    "                table[i,w] = table[i-1,w]\n",
    "\n",
    "    picks = []\n",
    "    K = capacity\n",
    "\n",
    "    for i in range(n_items,0,-1):\n",
    "        if keep[i,K] == 1:\n",
    "            picks.append(i)\n",
    "            K -= weights[i-1]\n",
    "\n",
    "    picks.sort()\n",
    "    picks = [x-1 for x in picks] # change to 0-index\n",
    "\n",
    "    if return_all:\n",
    "        max_val = table[n_items,capacity]\n",
    "        return picks,max_val\n",
    "    return picks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_summary(ypred, cps, n_frames, nfps, positions, proportion=0.15, method='knapsack'):\n",
    "    \"\"\"\n",
    "        Generate keyshot-based video summary. i.e. a binary vector\n",
    "\n",
    "    Args:\n",
    "        ypred: predicted importance scores.\n",
    "        cps: change points, 2D matrix, each row contains a segment.\n",
    "        n_frames: original number of frames.\n",
    "        nfps: number of frames per segment.\n",
    "        positions: positions of subsampled frames in the original video.\n",
    "        proportion: length of video summary (compared to original video length).\n",
    "        method: defines how shots are selected, ['knapsack', 'rank'].\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n_segs = cps.shape[0]\n",
    "\n",
    "    # Frame Score\n",
    "    frame_scores = np.zeros((n_frames), dtype=np.float32)\n",
    "    if positions.dtype != int:\n",
    "        positions = positions.astype(np.int32)\n",
    "\n",
    "    if positions[-1] != n_frames:\n",
    "        positions = np.concatenate([positions, [n_frames]])\n",
    "\n",
    "    for idx in range(len(positions) - 1):\n",
    "        pos_cur, pos_next = positions[idx], positions[idx+1]\n",
    "\n",
    "        if idx == len(ypred):\n",
    "            frame_scores[pos_cur:pos_next] = 0\n",
    "        else:\n",
    "            frame_scores[pos_cur:pos_next] = ypred[idx]\n",
    "\n",
    "    # Segment Score\n",
    "    seg_score = []\n",
    "    for seg_idx in range(n_segs):\n",
    "        pos_start, pos_end = int(cps[seg_idx, 0]), int(cps[seg_idx, 1]+1)\n",
    "        scores = frame_scores[pos_start: pos_end]\n",
    "        seg_score.append(float(scores.mean()))\n",
    "\n",
    "    limits = int(math.floor(n_frames * proportion))\n",
    "\n",
    "    if method == 'knapsack':\n",
    "        picks = knapsack_dp(seg_score, nfps, n_segs, limits)\n",
    "    elif method == 'rank':\n",
    "        order = np.argsort(seg_score)[::-1].tolist()\n",
    "        picks = []\n",
    "        total_len = 0\n",
    "\n",
    "        for idx in order:\n",
    "            if total_len + nfps[idx] < limits:\n",
    "                picks.append(idx)\n",
    "                total_len += nfps[idx]\n",
    "\n",
    "    else:\n",
    "        raise KeyError(\"Unknown method {}\".format(method))\n",
    "\n",
    "    summary = np.zeros((1), dtype=np.float32) # this element should be deleted\n",
    "    for seg_idx in range(n_segs):\n",
    "        nf = nfps[seg_idx]\n",
    "        if seg_idx in picks:\n",
    "            tmp = np.ones((nf), dtype=np.float32)\n",
    "        else:\n",
    "            tmp = np.zeros((nf), dtype=np.float32)\n",
    "\n",
    "        summary = np.concatenate((summary, tmp))\n",
    "\n",
    "    summary = np.delete(summary, 0) # delete the first element\n",
    "    return summary\n",
    "\n",
    "def evaluate_summary(machine_summary, user_summary, eval_metric='avg'):\n",
    "    \"\"\"\n",
    "        Compare machine summary with user summary (Keyshot-based).\n",
    "\n",
    "    Args:\n",
    "        machine_summary: summary by machine\n",
    "        user_summary: summary by user(annotation)\n",
    "        eval_metric: {'avg', 'max'}\n",
    "            'avg' : average results of comparing multiple human summaries.\n",
    "            'max' : takes the maximum(best) out of multiple comparisons.\n",
    "    \"\"\"\n",
    "\n",
    "    machine_summary = machine_summary.astype(np.float32)\n",
    "    user_summary = user_summary.astype(np.float32)\n",
    "    n_users, n_frames = user_summary.shape\n",
    "\n",
    "    # binarization\n",
    "    machine_summary[machine_summary > 0] = 1\n",
    "    user_summary[user_summary > 0] = 1\n",
    "\n",
    "    if len(machine_summary) > n_frames:\n",
    "        machine_summary = machine_summary[:n_frames]\n",
    "    elif len(machine_summary) < n_frames:\n",
    "        zero_padding = np.zeros((n_frames - len(machine_summary)))\n",
    "        machine_summary = np.concatenate([machine_summary, zero_padding])\n",
    "\n",
    "    f_scores = []\n",
    "    prec_arr = []\n",
    "    rec_arr = []\n",
    "\n",
    "    for user_idx in range(n_users):\n",
    "        gt_summary = user_summary[user_idx, :]\n",
    "        overlap_duration = (machine_summary * gt_summary).sum()\n",
    "        precision = overlap_duration / (machine_summary.sum() + 1e-8)\n",
    "        recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
    "        if precision == 0 and recall == 0:\n",
    "            f_score = 0.\n",
    "        else:\n",
    "            f_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "        f_scores.append(f_score)\n",
    "        prec_arr.append(precision)\n",
    "        rec_arr.append(recall)\n",
    "\n",
    "    if eval_metric == 'avg':\n",
    "        final_f_score = np.mean(f_scores)\n",
    "        final_prec = np.mean(prec_arr)\n",
    "        final_rec = np.mean(rec_arr)\n",
    "\n",
    "    elif eval_metric == 'max':\n",
    "        final_f_score = np.max(f_scores)\n",
    "        max_idx = np.argmax(f_scores)\n",
    "        final_prec = prec_arr[max_idx]\n",
    "        final_rec = rec_arr[max_idx]\n",
    "\n",
    "    return final_f_score, final_prec, final_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_reward(seq, actions, ignore_far_sim = True, temp_dist_thre = 20, use_gpu = False):\n",
    "    \"\"\"\n",
    "    Compute diversity reward and representativeness reward\n",
    "\n",
    "    Args:\n",
    "        seq: sequence of features, shape (1, seq_len, dim)\n",
    "        actions: binary action sequence, shape (1, seq_len, 1)\n",
    "        ignore_far_sim (bool): whether to ignore temporally distant similarity (default: True)\n",
    "        temp_dist_thre (int): threshold for ignoring temporally distant similarity (default: 20)\n",
    "        use_gpu (bool): whether to use GPU\n",
    "    \"\"\"\n",
    "    _seq = seq.detach()\n",
    "    _actions = actions.detach()\n",
    "    pick_idxs = _actions.squeeze().nonzero().squeeze()\n",
    "    num_picks = len(pick_idxs) if pick_idxs.ndimension() > 0 else 1\n",
    "    \n",
    "    if num_picks == 0:\n",
    "        # give zero reward is no frames are selected\n",
    "        reward = torch.tensor(0.)\n",
    "        if use_gpu: reward = reward.cuda()\n",
    "        return reward\n",
    "\n",
    "    _seq = _seq.squeeze()\n",
    "    n = _seq.size(0)\n",
    "\n",
    "    # compute diversity reward\n",
    "    if num_picks == 1:\n",
    "        reward_div = torch.tensor(0.)\n",
    "        if use_gpu: reward_div = reward_div.cuda()\n",
    "    else:\n",
    "        normed_seq = _seq / _seq.norm(p=2, dim=1, keepdim=True)\n",
    "        dissim_mat = 1. - torch.matmul(normed_seq, normed_seq.t()) # dissimilarity matrix [Eq.4]\n",
    "        dissim_submat = dissim_mat[pick_idxs,:][:,pick_idxs]\n",
    "        if ignore_far_sim:\n",
    "            # ignore temporally distant similarity\n",
    "            pick_mat = pick_idxs.expand(num_picks, num_picks)\n",
    "            temp_dist_mat = torch.abs(pick_mat - pick_mat.t())\n",
    "            dissim_submat[temp_dist_mat > temp_dist_thre] = 1.\n",
    "        reward_div = dissim_submat.sum() / (num_picks * (num_picks - 1.)) # diversity reward [Eq.3]\n",
    "\n",
    "    # compute representativeness reward\n",
    "    dist_mat = torch.pow(_seq, 2).sum(dim=1, keepdim=True).expand(n, n)\n",
    "    dist_mat = dist_mat + dist_mat.t()\n",
    "    dist_mat.addmm_(1, -2, _seq, _seq.t())\n",
    "    dist_mat = dist_mat[:,pick_idxs]\n",
    "    dist_mat = dist_mat.min(1, keepdim=True)[0]\n",
    "    reward_rep = torch.exp(-dist_mat.mean())\n",
    "\n",
    "    # combine the two rewards\n",
    "    reward = (reward_div + reward_rep) * 0.5\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_F_score(probs, dataset, key, use_gpu):\n",
    "    \n",
    "    eval_metric = 'avg' if METRIC == 'tvsum' else 'max'\n",
    "\n",
    "    if VERBOSE: table = [[\"No.\", \"Video\", \"F-Score\"]]\n",
    "    seq = dataset[key]['features'][...]\n",
    "    seq = torch.from_numpy(seq).unsqueeze(0)\n",
    "\n",
    "    if use_gpu: seq = seq.cuda()\n",
    "    probs = probs.data.cpu().squeeze().numpy()\n",
    "    \n",
    "    cps = dataset[key]['change_points'][...]\n",
    "    num_frames = dataset[key]['n_frames'][()]\n",
    "    nfps = dataset[key]['n_frame_per_seg'][...].tolist()\n",
    "    positions = dataset[key]['picks'][...]\n",
    "    user_summary = dataset[key]['user_summary'][...]\n",
    "\n",
    "    machine_summary = generate_summary(probs, cps, num_frames, nfps, positions)\n",
    "    fm, _, _ = evaluate_summary(machine_summary, user_summary, eval_metric)\n",
    "    \n",
    "    fm = np.mean(fm)#确保可以打印\n",
    "    #print(\"compute F-sorce;F-Score {:.1%}\".format(fm))\n",
    "\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_root_reward(change_index, update_idx, seq, global_all_norm, dataset, train_key, use_gpu):\n",
    "    global_all_norm = global_all_norm[0]\n",
    "    reward = 0\n",
    "    F_score_list = torch.zeros(Local_Seq_Len)\n",
    "    Max_F_score = 0\n",
    "    \n",
    "    length = len(seq)\n",
    "    seq = torch.from_numpy(seq).unsqueeze(0)\n",
    "    actions = torch.zeros(1, length, 1)\n",
    "    for i in range(Local_Seq_Len):\n",
    "        actions[0][update_idx[i]] = 1\n",
    "    \n",
    "    for i in range(Local_Seq_Len):\n",
    "        F_score_list[i] = compute_F_score(actions, dataset, train_key, use_gpu)\n",
    "        Max_F_score = max(F_score_list[i], Max_F_score)\n",
    "    \n",
    "    if F_score_list[change_index] == Max_F_score:\n",
    "        reward = max_epis + compute_reward(seq, actions)\n",
    "    else:\n",
    "        reward = epis + compute_reward(seq, actions)\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_leaf_reward(change_index, update_idx, seq, dataset, train_key, use_gpu):\n",
    "    reward = 0\n",
    "    length = len(seq)\n",
    "    seq = torch.from_numpy(seq).unsqueeze(0)\n",
    "    actions = torch.zeros(1, length, 1)\n",
    "    for i in range(Local_Seq_Len):\n",
    "        actions[0][update_idx[i]] = 1\n",
    "        \n",
    "    reward = epis + compute_reward(seq, actions)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inital_data_process(seq):\n",
    "    idx = choose_ten_frame(len(seq))\n",
    "    global_feature_1 = seq[idx[0]]\n",
    "    global_feature_2 = seq[idx[1]]\n",
    "    global_feature_3 = seq[idx[2]]\n",
    "    global_feature_4 = seq[idx[3]]\n",
    "    global_feature_5 = seq[idx[4]]\n",
    "    global_feature_6 = seq[idx[5]]\n",
    "    global_feature_7 = seq[idx[6]]\n",
    "    global_feature_8 = seq[idx[7]]\n",
    "    global_feature_9 = seq[idx[8]]\n",
    "    global_feature_10 = seq[idx[9]]\n",
    "    \n",
    "    global_feature_concate = np.concatenate([global_feature_1, global_feature_2, global_feature_3, global_feature_4, global_feature_5, \\\n",
    "                                              global_feature_6, global_feature_7, global_feature_8, global_feature_9, global_feature_10], axis=0)\n",
    "    idx_list = [i + 1 for i in range(Global_Seq_Len)]\n",
    "    five_unit = int(len(seq) / SEGMENT_LEN)\n",
    "    num_units = len(seq)\n",
    "    return global_feature_concate, idx, idx_list, five_unit, num_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_left_move_range(idx, index, current_id, five_unit, num_units):\n",
    "    update_id = current_id\n",
    "    update_idx = []\n",
    "    for i in range(len(idx)):\n",
    "        update_idx = idx\n",
    "    abnormal_done = 1\n",
    "    num_units = int(num_units)\n",
    "\n",
    "    if update_id < 0 or update_id > num_units:\n",
    "        abnormal_done = 0\n",
    "    else:\n",
    "        update_id = update_id - five_unit\n",
    "        \n",
    "        if update_id < 0:\n",
    "            update_id = 0\n",
    "        if update_id >= num_units:\n",
    "            update_id = num_units - 1\n",
    "        \n",
    "        if index == 0:\n",
    "            if update_id >= idx[index + 1]:\n",
    "                abnormal_done = 0\n",
    "        elif index == len(idx) - 1:\n",
    "            if update_id <= idx[index - 1]:\n",
    "                abnormal_done = 0\n",
    "        else:\n",
    "            if update_id >= idx[index + 1] or update_id <= idx[index - 1]:\n",
    "                abnormal_done = 0\n",
    "    update_idx[index] = update_id\n",
    "  \n",
    "    if abnormal_done == 0:\n",
    "        return torch.from_numpy(np.array(idx)), current_id, current_id, abnormal_done\n",
    "    return torch.from_numpy(np.array(update_idx)), update_id, current_id, abnormal_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_right_move_range(idx, index, current_id, five_unit, num_units):\n",
    "    update_id = current_id\n",
    "    update_idx = []\n",
    "    for i in range(len(idx)):\n",
    "        update_idx = idx\n",
    "    abnormal_done = 1\n",
    "    num_units = int(num_units)\n",
    "    \n",
    "    if update_id < 0 or update_id > num_units:\n",
    "        abnormal_done = 0\n",
    "    else:\n",
    "        update_id = update_id + five_unit\n",
    "        \n",
    "        if update_id < 0:\n",
    "            update_id = 0\n",
    "        if update_id >= num_units:\n",
    "            update_id = num_units - 1\n",
    "        \n",
    "        if index == 0:\n",
    "            if update_id >= idx[index + 1]:\n",
    "                abnormal_done = 0\n",
    "        elif index == len(idx) - 1:\n",
    "            if update_id <= idx[index - 1]:\n",
    "                abnormal_done = 0\n",
    "        else:\n",
    "            if update_id >= idx[index + 1] or update_id <= idx[index - 1]:\n",
    "                abnormal_done = 0\n",
    "    update_idx[index] = update_id\n",
    "    if abnormal_done == 0:\n",
    "        return torch.from_numpy(np.array(idx)), current_id, current_id, abnormal_done\n",
    "  \n",
    "    return torch.from_numpy(np.array(update_idx)), update_id, current_id, abnormal_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_left_offset_range(idx, index, current_id, five_unit, num_units):\n",
    "    update_id = current_id\n",
    "    update_idx = []\n",
    "    for i in range(len(idx)):\n",
    "        update_idx = idx\n",
    "    abnormal_done = 1\n",
    "    num_units = int(num_units)\n",
    "    \n",
    "    if update_id < 0 or update_id > num_units:\n",
    "        abnormal_done = 0\n",
    "    else:\n",
    "        update_id = update_id - 1\n",
    "        \n",
    "        if update_id < 0:\n",
    "            update_id = 0\n",
    "        if update_id >= num_units:\n",
    "            update_id = num_units - 1\n",
    "        \n",
    "        if index == 0:\n",
    "            if update_id >= idx[index + 1]:\n",
    "                abnormal_done = 0\n",
    "        elif index == len(idx) - 1:\n",
    "            if update_id <= idx[index - 1]:\n",
    "                abnormal_done = 0\n",
    "        else:\n",
    "            if update_id >= idx[index + 1] or update_id <= idx[index - 1]:\n",
    "                abnormal_done = 0\n",
    "    update_idx[index] = update_id\n",
    "    if abnormal_done == 0:\n",
    "        return torch.from_numpy(np.array(idx)), current_id, current_id, abnormal_done\n",
    "\n",
    "    return torch.from_numpy(np.array(update_idx)), update_id, current_id, abnormal_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_right_offset_range(idx, index, current_id, five_unit, num_units):\n",
    "    update_id = current_id\n",
    "    update_idx = []\n",
    "    for i in range(len(idx)):\n",
    "        update_idx = idx\n",
    "    abnormal_done = 1\n",
    "    num_units = int(num_units)\n",
    "    \n",
    "    if update_id < 0 or update_id > num_units:\n",
    "        abnormal_done = 0\n",
    "    else:\n",
    "        update_id = update_id + 1\n",
    "        \n",
    "        if update_id < 0:\n",
    "            update_id = 0\n",
    "        if update_id >= num_units:\n",
    "            update_id = num_units - 1\n",
    "        \n",
    "        if index == 0:\n",
    "            if update_id >= idx[index + 1]:\n",
    "                abnormal_done = 0\n",
    "        elif index == len(idx) - 1:\n",
    "            if update_id <= idx[index - 1]:\n",
    "                abnormal_done = 0\n",
    "        else:\n",
    "            if update_id >= idx[index + 1] or update_id <= idx[index - 1]:\n",
    "                abnormal_done = 0\n",
    "    update_idx[index] = update_id\n",
    "    if abnormal_done == 0:\n",
    "        return torch.from_numpy(np.array(idx)), current_id, current_id, abnormal_done\n",
    "\n",
    "    return torch.from_numpy(np.array(update_idx)), update_id, current_id, abnormal_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freeze_net(net, global_flag):\n",
    "\n",
    "    if global_flag == True:\n",
    "        # don't compute the gradient of local polict network\n",
    "        ct = 0\n",
    "        for child in net.children():\n",
    "            ct +=1\n",
    "            if ct == 6:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "            else:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = True\n",
    "    else:\n",
    "        # don't compute the gradient of global polict network\n",
    "        ct = 0\n",
    "        for child in net.children():\n",
    "            ct +=1\n",
    "            if ct == 5:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "            else:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_keys, use_gpu):\n",
    "    print(\"===> Evaluation\")\n",
    "    dataset = h5py.File(DATASET, 'r')\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        if use_gpu: model = model.cuda()\n",
    "        fms = []\n",
    "        eval_metric = 'avg' if METRIC == 'tvsum' else 'max'\n",
    "        \n",
    "        test_dataset = Charades_dataset(test_keys)\n",
    "        testloader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0)\n",
    "        \n",
    "        for batch_idx, key in enumerate(testloader):\n",
    "            seq = dataset[key[0]]['features'][...]\n",
    "            seq_furtrue = torch.from_numpy(seq).unsqueeze(0) \n",
    "            global_feature_concate, idx, idx_list, five_unit, num_units = inital_data_process(seq)#[1024]\n",
    "            global_feature_concate = torch.from_numpy(global_feature_concate).unsqueeze(0)        #[batch_size,1024]\n",
    "            hidden_state = torch.zeros(BATCH_SIZE, Visual_Feature_Dim)\n",
    "            current_feature_concate = global_feature_concate\n",
    "            BEST_F_score = 0.0\n",
    "\n",
    "            for step in range(NUM_STEPS):\n",
    "                if use_gpu: \n",
    "                    hidden_state = hidden_state.cuda()\n",
    "                    current_feature_concate = current_feature_concate.cuda()\n",
    "                    global_feature_concate = global_feature_concate.cuda()\n",
    "                    seq_furtrue = seq_furtrue.cuda()\n",
    "\n",
    "                hidden_state, global_policy, move_policy, iou_out2 = model(seq_furtrue, global_feature_concate, current_feature_concate, hidden_state)\n",
    "\n",
    "\n",
    "                probs = iou_out2.data.cpu().squeeze().numpy()\n",
    "                cps = dataset[key[0]]['change_points'][...]\n",
    "                num_frames = dataset[key[0]]['n_frames'][()]\n",
    "                nfps = dataset[key[0]]['n_frame_per_seg'][...].tolist()\n",
    "                positions = dataset[key[0]]['picks'][...]\n",
    "                user_summary = dataset[key[0]]['user_summary'][...]\n",
    "\n",
    "                machine_summary = generate_summary(probs, cps, num_frames, nfps, positions)\n",
    "                fm, _, _ = evaluate_summary(machine_summary, user_summary, eval_metric)\n",
    "\n",
    "                if fm > BEST_F_score:\n",
    "                    BEST_F_score = fm\n",
    "\n",
    "                global_policy_prob = F.softmax(global_policy, dim = 1)\n",
    "                global_policy_action = global_policy_prob.max(1, keepdim = True)[1].data.cpu().numpy()[:, 0]\n",
    "\n",
    "\n",
    "                update_idx = idx\n",
    "                local_abnormal_done = torch.ones(BATCH_SIZE)\n",
    "\n",
    "                for i in range(BATCH_SIZE):\n",
    "\n",
    "                    for local_id in range(Local_Seq_Len):\n",
    "                        if global_policy_action[i] == local_id:      #表示对第几帧进行操作\n",
    "                            move_policy_prob = F.softmax(move_policy[i], dim = 0)\n",
    "                            move_policy_action = move_policy_prob.max(0, keepdim=True)[1].data.cpu().numpy()\n",
    "\n",
    "                            if move_policy_action == 0:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_left_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 1:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_right_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 2:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_left_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 3:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_right_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            else:\n",
    "                                local_abnormal_done[i] = 0\n",
    "                \n",
    "                currrent_feature_1 = seq[update_idx[0]]\n",
    "                currrent_feature_2 = seq[update_idx[1]]\n",
    "                currrent_feature_3 = seq[update_idx[2]]\n",
    "                currrent_feature_4 = seq[update_idx[3]]\n",
    "                currrent_feature_5 = seq[update_idx[4]]\n",
    "                currrent_feature_6 = seq[update_idx[5]]\n",
    "                currrent_feature_7 = seq[update_idx[6]]\n",
    "                currrent_feature_8 = seq[update_idx[7]]\n",
    "                currrent_feature_9 = seq[update_idx[8]]\n",
    "                currrent_feature_10 = seq[update_idx[9]]\n",
    "                \n",
    "                current_feature_concate = torch.from_numpy(np.concatenate([currrent_feature_1, currrent_feature_2, currrent_feature_3, currrent_feature_4, currrent_feature_5, \\\n",
    "                                                              currrent_feature_6, currrent_feature_7, currrent_feature_8, currrent_feature_9, currrent_feature_10], axis=0)).unsqueeze(0)\n",
    "                    \n",
    "                \n",
    "                \n",
    "            fms.append(BEST_F_score)\n",
    "    mean_fm = np.mean(fms)\n",
    "    print(\"Average F-Score {:.1%}\".format(mean_fm))\n",
    "    dataset.close()\n",
    "    model.train()\n",
    "    return mean_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, use_gpu):\n",
    "    splits = read_json(SPLIT)\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    assert SPLIT_ID < len(splits), \"split_id (got {}) exceeds {}\".format(SPLIT_ID, len(splits ))\n",
    "    split = splits[SPLIT_ID]\n",
    "    test_keys = split[\"test_keys\"]\n",
    "    return evaluate(model, test_keys, use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Charades_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, keys):\n",
    "        self.keys = keys\n",
    "        self.len = len(keys)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.keys[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DSN(nn.Module):\n",
    "    \"\"\" Deep Summarization Network \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim = 1024, hid_dim = 256, num_layers = 1, cell = 'lstm'):\n",
    "        super(DSN, self).__init__()\n",
    "        assert cell in ['lstm', 'gru'], \"cell must be either 'lstm' or 'gru\"\n",
    "\n",
    "        if cell == 'lstm':\n",
    "            self.rnn = nn.LSTM(in_dim, hid_dim, num_layers = num_layers, bidirectional = True, batch_first = True)\n",
    "        elif cell == 'gru':\n",
    "            self.rnn = nn.GRU(in_dim, hid_dim, num_layers = num_layers, bidirectional = True, batch_first = True)\n",
    "\n",
    "        self.fc = nn.Linear(hid_dim * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, _ = self.rnn(x)\n",
    "        p = T.sigmoid(self.fc(h))\n",
    "\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PRL_VS(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \" global policy denotes the root policy, left policy denotes the left policy\"\n",
    "        super(PRL_VS, self).__init__()\n",
    "        self.visual_feature_dim = Visual_Feature_Dim\n",
    "        \n",
    "        self.gobal_fc = nn.Linear(self.visual_feature_dim * Global_Seq_Len, 1024)\n",
    "        self.local_fc = nn.Linear(self.visual_feature_dim * Local_Seq_Len, 1024)\n",
    "        \n",
    "        self.state_fc = nn.Linear(1024 * 3, 1024)\n",
    "\n",
    "        self.gru = nn.GRUCell(1024, 1024)\n",
    "        \n",
    "        self.global_policy = nn.Linear(1024, Local_Seq_Len)#5 \n",
    "        self.move_policy = nn.Linear(1024, 4)#6\n",
    "        self.DSN = DSN()\n",
    "\n",
    "        # Initializing weights\n",
    "        self.apply(weights_init)\n",
    "        self.global_policy.weight.data = normalized_columns_initializer(self.global_policy.weight.data, 0.01)\n",
    "        self.global_policy.bias.data.fill_(0)\n",
    "\n",
    "        self.move_policy.weight.data = normalized_columns_initializer(self.move_policy.weight.data, 0.01)\n",
    "        self.move_policy.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, seq, global_feature, local_feature, hidden_state):\n",
    "    \n",
    "        global_feature =self.gobal_fc(global_feature)\n",
    "        global_feature_norm = F.normalize(global_feature, p = 2, dim = 1)\n",
    "        global_feature_norm =  F.relu(global_feature_norm)#[batch_size, 1024]\n",
    "\n",
    "        local_feature = self.local_fc(local_feature)\n",
    "        local_feature_norm = F.normalize(local_feature, p = 2, dim = 1)\n",
    "        local_feature_norm = F.relu(local_feature_norm)#[batch_size, 1024]\n",
    "    \n",
    "        \n",
    "        #gate-attention\n",
    "        assert local_feature_norm.size() == global_feature_norm.size()\n",
    "        local_attention_feature = local_feature_norm * global_feature_norm#[batch_size, 1024]\n",
    "        \n",
    "        state_feature = torch.cat([local_attention_feature, global_feature_norm, local_feature_norm], 1)#[batch_size, 3072]\n",
    "\n",
    "\n",
    "        state_feature = self.state_fc(state_feature)\n",
    "        state_feature = F.relu(state_feature)#[batch_size, 1024]\n",
    "\n",
    "        hidden_state = self.gru(state_feature, hidden_state)#[batch_size, 1024]\n",
    "\n",
    "        global_policy = self.global_policy(hidden_state)\n",
    "        move_policy = self.move_policy(hidden_state)\n",
    "\n",
    "        iou_out2 = self.DSN(seq)\n",
    "\n",
    "        return hidden_state, global_policy, move_policy, iou_out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    torch.manual_seed(SEED)\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "\n",
    "    if use_gpu:\n",
    "        print(\"Currently using GPU\")\n",
    "        cudnn.benchmark = True\n",
    "        torch.cuda.manual_seed(SEED)\n",
    "    else:\n",
    "        print(\"Currently using CPU\")    \n",
    "\n",
    "    print(\"Initialize dataset {}\".format(DATASET))\n",
    "    dataset = h5py.File(DATASET, 'r')\n",
    "    num_videos = len(dataset.keys())\n",
    "    splits = read_json(SPLIT)\n",
    "\n",
    "    if not TEST:\n",
    "        assert SPLIT_ID < len(splits), \"split_id (got {}) exceeds {}\".format(SPLIT_ID, len(splits))\n",
    "        split = splits[SPLIT_ID]\n",
    "        train_keys = split[\"train_keys\"]\n",
    "        test_keys = split[\"test_keys\"]\n",
    "        print(\"# total videos {}. # train videos {}. # test videos {}.\".format(num_videos, len(train_keys), len(test_keys)))\n",
    "        \n",
    "    model = PRL_VS()\n",
    "    print(\"Initialize model\")\n",
    "    print(\"Model Size: {:.5f}M\".format(sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LR, weight_decay = WEIGHT_DECAY)\n",
    "    \n",
    "    if STEP_SIZE > 0:\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size = STEP_SIZE, gamma = GAMMA)\n",
    "    if use_gpu:\n",
    "        model = nn.DataParallel(model).cuda()\n",
    "        \n",
    "    if RESUME:\n",
    "        print(\"Retrain...\")\n",
    "        model_save_path = os.path.join(LOAD_DIR)\n",
    "        print(\"Loading checkpoint from '{}'\".format(LOAD_DIR))\n",
    "        checkpoint = torch.load(LOAD_DIR, map_location='cpu')\n",
    "        if use_gpu:\n",
    "            model.module.load_state_dict(checkpoint)\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "        start_epoch = START_EPOCH\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        \n",
    "    print(\"===> Start training\")\n",
    "    model.train()\n",
    "    iteration = 0\n",
    "    global_flag = False\n",
    "    baselines = {key: 0. for key in train_keys} # baseline rewards for videos\n",
    "    reward_writers = {key: [] for key in train_keys} # record reward changes for each video\n",
    "    \n",
    "    train_dataset = Charades_dataset(train_keys)\n",
    "    trainloader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(start_epoch, start_epoch + MAX_EPOCH): \n",
    "        sum_loss = 0.0\n",
    "        Max_F_score = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_idx, key in enumerate(trainloader):\n",
    "            seq = dataset[key[0]]['features'][...] # sequence of features, (seq_len, dim)\n",
    "            seq_furtrue = torch.from_numpy(seq).unsqueeze(0)\n",
    "            global_feature_concate, idx, idx_list, five_unit, num_units = inital_data_process(seq)#[1024]\n",
    "            global_feature_concate = torch.from_numpy(global_feature_concate).unsqueeze(0)#[batch_size,1024]\n",
    "            inital_feature_concate = global_feature_concate\n",
    "            current_feature_concate = inital_feature_concate\n",
    "            hidden_state = torch.zeros(BATCH_SIZE, Visual_Feature_Dim)\n",
    "            \n",
    "\n",
    "            if iteration % Switch_Iteration == 0:\n",
    "                global_flag = not global_flag\n",
    "                freeze_net(model, global_flag)\n",
    "                \n",
    "                \n",
    "            for step in range(NUM_STEPS):\n",
    "                    \n",
    "                if use_gpu: \n",
    "                    hidden_state = hidden_state.cuda()\n",
    "                    current_feature_concate = current_feature_concate.cuda()\n",
    "                    global_feature_concate = global_feature_concate.cuda()\n",
    "                    seq_furtrue = seq_furtrue.cuda()\n",
    "                    \n",
    "                #模型输出\n",
    "                hidden_state, global_policy, move_policy, iou_out2 = model(seq_furtrue, global_feature_concate, current_feature_concate, hidden_state)\n",
    "\n",
    "                global_policy_prob = F.softmax(global_policy, dim = 1)\n",
    "                    \n",
    "                if global_flag == True: \n",
    "                    global_policy_action = global_policy_prob.multinomial(num_samples = 1).data\n",
    "                    global_policy_action = global_policy_action.cpu().numpy()[:, 0]\n",
    "                else: \n",
    "                    global_policy_action = global_policy_prob.max(1, keepdim = True)[1].data.cpu().numpy()[:, 0]\n",
    "\n",
    "                update_idx = idx\n",
    "                local_abnormal_done = torch.ones(BATCH_SIZE)\n",
    "                global_all_norm = torch.zeros(BATCH_SIZE, Local_Seq_Len, Local_Seq_Len)#训练根策略表示最后移动到的位置\n",
    "                global_abnormal_done_all_norm = torch.ones(BATCH_SIZE, Local_Seq_Len)#训练根策略时记录异常情况\n",
    "                \n",
    "                if use_gpu: \n",
    "                    global_all_norm = global_all_norm.cuda()\n",
    "                    global_abnormal_done_all_norm = global_abnormal_done_all_norm.cuda()   \n",
    "\n",
    "                for i in range(BATCH_SIZE):\n",
    "\n",
    "                    expect_reward = 0.0\n",
    "                    expect_cost = 0.0\n",
    "                    expect_loss = 0.0\n",
    "\n",
    "                    if global_flag == True:\n",
    "                        move_policy_prob = F.softmax(move_policy[i], dim = 0)\n",
    "                        move_policy_action = move_policy_prob.max(0, keepdim=True)[1].data.cpu().numpy()\n",
    "\n",
    "                        for local_id in range(Local_Seq_Len):\n",
    "                            if move_policy_action == 0:\n",
    "                                global_all_norm[i][local_id], _, _, global_abnormal_done_all_norm[i][local_id] = determine_left_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 1:\n",
    "                                global_all_norm[i][local_id], _, _, global_abnormal_done_all_norm[i][local_id] = determine_right_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 2:\n",
    "                                global_all_norm[i][local_id], _, _, global_abnormal_done_all_norm[i][local_id] = determine_left_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 3:\n",
    "                                global_all_norm[i][local_id], _, _, global_abnormal_done_all_norm[i][local_id] = determine_right_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            else:\n",
    "                                global_abnormal_done_all_norm[i][local_id] = 0\n",
    "\n",
    "                    for local_id in range(Local_Seq_Len):\n",
    "                        if global_policy_action[i] == local_id:      #表示对第几帧进行操作\n",
    "                            move_policy_prob = F.softmax(move_policy[i], dim = 0)\n",
    "                            if global_flag == True:  # train the global_layer\n",
    "                                move_policy_action = move_policy_prob.max(0, keepdim = True)[1].data.cpu().numpy()\n",
    "                            else:\n",
    "                                move_policy_action = move_policy_prob.multinomial(num_samples=1).data\n",
    "                                move_policy_action = move_policy_action.cpu().numpy()[0]\n",
    "                            if move_policy_action == 0:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_left_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 1:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_right_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 2:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_left_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 3:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_right_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            else:\n",
    "                                local_abnormal_done[i] = 0\n",
    "\n",
    "                    #对abnormal进行处理\n",
    "                        \n",
    "                    #更新数据\n",
    "                    currrent_feature_1 = seq[update_idx[0]]\n",
    "                    currrent_feature_2 = seq[update_idx[1]]\n",
    "                    currrent_feature_3 = seq[update_idx[2]]\n",
    "                    currrent_feature_4 = seq[update_idx[3]]\n",
    "                    currrent_feature_5 = seq[update_idx[4]]\n",
    "                    currrent_feature_6 = seq[update_idx[5]]\n",
    "                    currrent_feature_7 = seq[update_idx[6]]\n",
    "                    currrent_feature_8 = seq[update_idx[7]]\n",
    "                    currrent_feature_9 = seq[update_idx[8]]\n",
    "                    currrent_feature_10 = seq[update_idx[9]]\n",
    "                    current_feature_concate = torch.from_numpy(np.concatenate([currrent_feature_1, currrent_feature_2, currrent_feature_3, currrent_feature_4, currrent_feature_5, \\\n",
    "                                                              currrent_feature_6, currrent_feature_7, currrent_feature_8, currrent_feature_9, currrent_feature_10], axis=0)).unsqueeze(0)\n",
    "                    \n",
    "                    #计算reward\n",
    "                    change_index = global_policy_action[i]\n",
    "                    train_key = key[0]\n",
    "                    \n",
    "                    if global_flag == True:\n",
    "                        expect_reward = calculate_root_reward(change_index, update_idx, seq, global_all_norm, dataset, train_key, use_gpu)\n",
    "                    else:\n",
    "                        expect_reward = calculate_leaf_reward(change_index, update_idx, seq, dataset, train_key, use_gpu)\n",
    "                    \n",
    "                    m = Bernoulli(iou_out2)\n",
    "                    actions = m.sample()\n",
    "                    log_probs = m.log_prob(actions)\n",
    "                    expect_reward = log_probs.mean() * (expect_reward)\n",
    "                    \n",
    "                    expect_loss = BETA * (iou_out2.mean() - 0.5) ** 2 - expect_reward\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    expect_loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                    optimizer.step()\n",
    "                    sum_loss += expect_loss\n",
    "            \n",
    "            iteration += 1  \n",
    "            \n",
    "        elapsed = round(time.time() - start_time)\n",
    "        elapsed = str(datetime.timedelta(seconds = elapsed))\n",
    "        print(\"epoch {}/{}\\t Loss {:.8f}\\t {}\".format(epoch + 1, MAX_EPOCH, sum_loss, elapsed))\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            F_score = evaluate_model(model, use_gpu)\n",
    "            if F_score > Max_F_score:\n",
    "                model_state_dict = model.module.state_dict() if use_gpu else model.state_dict()\n",
    "                model_save_path = os.path.join(SAVE_DIR, 'model_epoch' + str(epoch) + '_'+ str(F_score) + '_' + str(DATASET_NAME) + '.pth.tar')\n",
    "                save_checkpoint(model_state_dict, model_save_path)\n",
    "                print(\"Model saved to {}\".format(model_save_path))\n",
    "                Max_F_score = F_score\n",
    "                \n",
    "    dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old evaluate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = PRL_VS()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "model_save_path = os.path.join('resualt/model_epoch104_0.40463972473017973_summe.pth.tar')\n",
    "print(\"Loading checkpoint from '{}'\".format(model_save_path))\n",
    "checkpoint = torch.load(model_save_path, map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint)\n",
    "evaluate_model(model, use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_point_to_segment(change_point):\n",
    "    segment = []\n",
    "    for i in range(len(change_point)):\n",
    "        segment.append(change_point[i][1])\n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_summe_gssummary(dataset, test_keys):\n",
    "    gold_standard = []\n",
    "    \n",
    "    for i in range(len(test_keys)):\n",
    "        gold_standard.append(\n",
    "            {\n",
    "                'gs_summary': dataset[test_keys[i]]['user_summary'][...],\n",
    "                'video': test_keys[i]\n",
    "            }\n",
    "        )\n",
    "    return gold_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knapsack(items, maxweight):\n",
    "    N = len(items)\n",
    "    W = maxweight\n",
    "\n",
    "    bestvalues = [[0] * (W + 1)\n",
    "                  for i in range(N + 1)]\n",
    "\n",
    "    for i, (value, weight) in enumerate(items):\n",
    "\n",
    "        for capacity in range(maxweight + 1):\n",
    "\n",
    "            if weight > capacity:\n",
    "                bestvalues[i + 1][capacity] = bestvalues[i][capacity]\n",
    "            else:\n",
    "                candidate1 = bestvalues[i][capacity]\n",
    "                candidate2 = bestvalues[i][capacity - weight] + value\n",
    "                bestvalues[i + 1][capacity] = max(candidate1, candidate2)\n",
    "\n",
    "    reconstruction = []\n",
    "    j = maxweight\n",
    "    for i in range(N, 0, -1):\n",
    "        if bestvalues[i][j] != bestvalues[i - 1][j]:\n",
    "            reconstruction.append(i - 1)\n",
    "            j -= items[i - 1][1]\n",
    "\n",
    "    reconstruction.reverse()\n",
    "\n",
    "    return bestvalues[len(items)][maxweight], reconstruction\n",
    "\n",
    "def summarize(score, segment, capacity, use_sum=False):\n",
    "        # generate summary\n",
    "        score = np.asarray(score).ravel()\n",
    "        f_idx = np.zeros_like(score)\n",
    "        \n",
    "        score = np.split(score, segment)\n",
    "        score = list(filter(lambda x: x.size, score)) # remove empty elements\n",
    "        \n",
    "        f_idx = np.split(f_idx, segment)\n",
    "        f_idx = list(filter(lambda x: x.size, f_idx)) # remove empty elements\n",
    "        \n",
    "        weights = [x.size for x in score]\n",
    "        \n",
    "        if use_sum:\n",
    "            values = [x.sum() for x in score]\n",
    "        else:\n",
    "            values = [x.mean() for x in score]\n",
    "        \n",
    "        _, selected_cut = knapsack([(v, w) for v, w in zip(values, weights)], capacity)\n",
    "        for si in selected_cut:\n",
    "            f_idx[si][:] = 1\n",
    "        \n",
    "        return np.hstack(f_idx)\n",
    "    \n",
    "def get_random_summary(N, segment, budget):\n",
    "    rand_score = np.random.random((N,))\n",
    "    rand_summary = summarize(rand_score, segment, int(N * budget))\n",
    "    return rand_summary\n",
    "\n",
    "def evaluate_baseline(verbose = True):\n",
    "    dataset = h5py.File(DATASET, 'r')\n",
    "    splits = read_json(SPLIT)\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    assert SPLIT_ID < len(splits), \"split_id (got {}) exceeds {}\".format(SPLIT_ID, len(splits ))\n",
    "    split = splits[SPLIT_ID]\n",
    "    test_keys = split[\"test_keys\"]\n",
    "    gt_summary = get_summe_gssummary(dataset, test_keys)\n",
    "    b_score = []\n",
    "    \n",
    "    for item in gt_summary:\n",
    "        gs_summary = item['gs_summary']\n",
    "        N = gs_summary.shape[1]\n",
    "        segment = change_point_to_segment(dataset[item['video']]['change_points'])\n",
    "        \n",
    "        rand_summary = get_random_summary(N, segment, budget=0.15)\n",
    "        \n",
    "        f1_scores = [f1_score(x, rand_summary) for x in gs_summary]\n",
    "        f1_min = min(f1_scores)\n",
    "        f1_mean = sum(f1_scores) / len(f1_scores)\n",
    "        f1_max = max(f1_scores)\n",
    "        \n",
    "        b_score.append((f1_min, f1_mean, f1_max))\n",
    "        \n",
    "        if verbose:\n",
    "            print('%25s | %6.2f | %6.2f | %6.2f |' % (item['video'], f1_min * 100, f1_mean * 100, f1_max * 100))\n",
    "        \n",
    "    b_score = np.array(b_score)\n",
    "    score_summary = b_score.mean(axis=0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('%25s | %6.2f | %6.2f | %6.2f |' % ('Avg.', score_summary[0] * 100, score_summary[1] * 100, score_summary[2] * 100))\n",
    "    \n",
    "    dataset.close()\n",
    "    return {'method': 'Random',\n",
    "            'min': score_summary[0],\n",
    "            'avg': score_summary[1],\n",
    "            'max': score_summary[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rc_func(metric):\n",
    "    if metric == 'kendalltau':\n",
    "        f = lambda x, y: kendalltau(rankdata(-x), rankdata(-y))\n",
    "    elif metric == 'spearmanr':\n",
    "        f = lambda x, y: spearmanr(x, y)\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_evaluate_method_F_score(summary, user_summary):\n",
    "    score = []\n",
    "    baseline_score = []\n",
    "    N = gs_summary.shape[1]\n",
    "    f1_scores = [f1_score(x, summary) for x in user_summary]\n",
    "    f1_min = min(f1_scores)\n",
    "    f1_mean = sum(f1_scores) / len(f1_scores)\n",
    "    f1_max = max(f1_scores)\n",
    "    score.append(f1_min * 100)\n",
    "    score.append(f1_mean * 100)\n",
    "    score.append(f1_max * 100)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_evaluate_method_metric(summary, user_summary, metric):\n",
    "    score = []\n",
    "    baseline_score = []\n",
    "    N = gs_summary.shape[1]\n",
    "    rc_func = get_rc_func(metric)\n",
    "    f1_scores = [rc_func(x, summary)[0] for x in user_summary]\n",
    "    f1_min = min(f1_scores)\n",
    "    f1_mean = sum(f1_scores) / len(f1_scores)\n",
    "    f1_max = max(f1_scores)\n",
    "    score.append(f1_min * 100)\n",
    "    score.append(f1_mean * 100)\n",
    "    score.append(f1_max * 100)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_evaluate_model(model, use_gpu, metric):\n",
    "    print(\"===> Evaluation\")\n",
    "    dataset = h5py.File(DATASET, 'r')\n",
    "    splits = read_json(SPLIT)\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    assert SPLIT_ID < len(splits), \"split_id (got {}) exceeds {}\".format(SPLIT_ID, len(splits ))\n",
    "    split = splits[SPLIT_ID]\n",
    "    test_keys = split[\"test_keys\"]\n",
    "    score_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        if use_gpu: model = model.cuda()\n",
    "        fms = []\n",
    "        eval_metric = 'avg' if METRIC == 'tvsum' else 'max'\n",
    "        \n",
    "        test_dataset = Charades_dataset(test_keys)\n",
    "        testloader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0)\n",
    "        for batch_idx, key in enumerate(testloader):\n",
    "            seq = dataset[key[0]]['features'][...]\n",
    "            seq_furtrue = torch.from_numpy(seq).unsqueeze(0) \n",
    "            global_feature_concate, idx, idx_list, five_unit, num_units = inital_data_process(seq)#[1024]\n",
    "            global_feature_concate = torch.from_numpy(global_feature_concate).unsqueeze(0)        #[batch_size,1024]\n",
    "            hidden_state = torch.zeros(BATCH_SIZE, Visual_Feature_Dim)\n",
    "            current_feature_concate = global_feature_concate\n",
    "            score = [0.0, 0.0, 0.0]\n",
    "            \n",
    "            for step in range(NUM_STEPS):\n",
    "                if use_gpu: \n",
    "                    hidden_state = hidden_state.cuda()\n",
    "                    current_feature_concate = current_feature_concate.cuda()\n",
    "                    global_feature_concate = global_feature_concate.cuda()\n",
    "\n",
    "                hidden_state, global_policy, move_policy, iou_out2 = model(seq_furtrue, global_feature_concate, current_feature_concate, hidden_state)\n",
    "\n",
    "\n",
    "                probs = iou_out2.data.cpu().squeeze().numpy()\n",
    "                cps = dataset[key[0]]['change_points'][...]\n",
    "                num_frames = dataset[key[0]]['n_frames'][()]\n",
    "                nfps = dataset[key[0]]['n_frame_per_seg'][...].tolist()\n",
    "                positions = dataset[key[0]]['picks'][...]\n",
    "                user_summary = dataset[key[0]]['user_summary'][...]\n",
    "\n",
    "                machine_summary = generate_summary(probs, cps, num_frames, nfps, positions)\n",
    "                new_score = new_evaluate_method_metric(machine_summary, user_summary, metric)\n",
    "                \n",
    "                score[0] = max(score[0], new_score[0])\n",
    "                score[1] = max(score[1], new_score[1])\n",
    "                score[2] = max(score[2], new_score[2])\n",
    "\n",
    "                global_policy_prob = F.softmax(global_policy, dim = 1)\n",
    "                global_policy_action = global_policy_prob.max(1, keepdim = True)[1].data.cpu().numpy()[:, 0]\n",
    "\n",
    "\n",
    "                update_idx = idx\n",
    "                local_abnormal_done = torch.ones(BATCH_SIZE)\n",
    "\n",
    "                for i in range(BATCH_SIZE):\n",
    "\n",
    "                    for local_id in range(Local_Seq_Len):\n",
    "                        if global_policy_action[i] == local_id:      #表示对第几帧进行操作\n",
    "                            move_policy_prob = F.softmax(move_policy[i], dim = 0)\n",
    "                            move_policy_action = move_policy_prob.max(0, keepdim=True)[1].data.cpu().numpy()\n",
    "\n",
    "                            if move_policy_action == 0:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_left_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 1:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_right_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 2:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_left_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 3:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_right_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            else:\n",
    "                                local_abnormal_done[i] = 0\n",
    "                \n",
    "                currrent_feature_1 = seq[update_idx[0]]\n",
    "                currrent_feature_2 = seq[update_idx[1]]\n",
    "                currrent_feature_3 = seq[update_idx[2]]\n",
    "                currrent_feature_4 = seq[update_idx[3]]\n",
    "                currrent_feature_5 = seq[update_idx[4]]\n",
    "                currrent_feature_6 = seq[update_idx[5]]\n",
    "                currrent_feature_7 = seq[update_idx[6]]\n",
    "                currrent_feature_8 = seq[update_idx[7]]\n",
    "                currrent_feature_9 = seq[update_idx[8]]\n",
    "                currrent_feature_10 = seq[update_idx[9]]\n",
    "                current_feature_concate = torch.from_numpy(np.concatenate([currrent_feature_1, currrent_feature_2, currrent_feature_3, currrent_feature_4, currrent_feature_5, \\\n",
    "                                                          currrent_feature_6, currrent_feature_7, currrent_feature_8, currrent_feature_9, currrent_feature_10], axis=0)).unsqueeze(0)\n",
    "                      \n",
    "    \n",
    "            score_list.append(score)\n",
    "        score_list = np.array(score_list)\n",
    "        score_summary = score_list.mean(axis = 0)\n",
    "    dataset.close()\n",
    "    model.train()\n",
    "    return {'method': 'machine',\n",
    "            'min': score_summary[0],\n",
    "            'avg': score_summary[1],\n",
    "            'max': score_summary[2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F_score_ run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    model = PRL_VS()\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    model_save_path = os.path.join('./resualt/best_resualt/tvsum_62.0/model_epoch4_0.62016888935977_tvsum.pth.tar')\n",
    "    print(\"Loading checkpoint from '{}'\".format(model_save_path))\n",
    "    checkpoint = torch.load(model_save_path, map_location = 'cpu')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    metric = 'spearmanr'#'spearmanr''kendalltau'\n",
    "    score_summary = new_evaluate_model(model, use_gpu, metric)\n",
    "    \n",
    "    print('evaluating baseline scores')\n",
    "    N = 100\n",
    "    res = Parallel(n_jobs = -1)( [delayed(evaluate_baseline)(verbose = False) for _ in range(N)] )\n",
    "    res.append(score_summary)\n",
    "    df = pd.DataFrame(res)\n",
    "    print(df[df.method == 'Random'][['min', 'avg', 'max']].describe())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new evaluate method（'spearmanr' or 'kendalltau'）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute rank order statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rc_func(metric):\n",
    "    if metric == 'kendalltau':\n",
    "        f = lambda x, y: kendalltau(rankdata(-x), rankdata(-y))\n",
    "    elif metric == 'spearmanr':\n",
    "        f = lambda x, y: spearmanr(x, y)\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_evaluate_metric(model, use_gpu, metric):\n",
    "    print(\"===> Evaluation ===> Metric:\" + metric)\n",
    "    dataset = h5py.File(DATASET, 'r')\n",
    "    user_anno_datasets = h5py.File('./datasets/new_summe_user_anno.h5', 'r')\n",
    "    splits = read_json(SPLIT)\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    assert SPLIT_ID < len(splits), \"split_id (got {}) exceeds {}\".format(SPLIT_ID, len(splits ))\n",
    "    split = splits[SPLIT_ID]\n",
    "    test_keys = split[\"test_keys\"]\n",
    "    score_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        if use_gpu: model = model.cuda()\n",
    "        \n",
    "        test_dataset = Charades_dataset(test_keys)\n",
    "        testloader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0)\n",
    "        score_list = []\n",
    "        for batch_idx, key in enumerate(testloader):\n",
    "            seq = dataset[key[0]]['features'][...]\n",
    "            seq_furtrue = torch.from_numpy(seq).unsqueeze(0) \n",
    "            global_feature_concate, idx, idx_list, five_unit, num_units = inital_data_process(seq)#[1024]\n",
    "            global_feature_concate = torch.from_numpy(global_feature_concate).unsqueeze(0)        #[batch_size,1024]\n",
    "            hidden_state = torch.zeros(BATCH_SIZE, Visual_Feature_Dim)\n",
    "            current_feature_concate = global_feature_concate\n",
    "            Best_score = - 100.0\n",
    "\n",
    "            for step in range(NUM_STEPS):\n",
    "                if use_gpu: \n",
    "                    hidden_state = hidden_state.cuda()\n",
    "                    current_feature_concate = current_feature_concate.cuda()\n",
    "                    global_feature_concate = global_feature_concate.cuda()\n",
    "                    seq_furtrue = seq_furtrue.cuda()\n",
    "\n",
    "                hidden_state, global_policy, move_policy, iou_out2 = model(seq_furtrue, global_feature_concate, current_feature_concate, hidden_state)\n",
    "                rc_func = get_rc_func(metric)\n",
    "\n",
    "\n",
    "                probs = iou_out2.data.cpu().squeeze().numpy()\n",
    "                user_anno = user_anno_datasets[key[0]]['user_anno'][...]\n",
    "                assert probs.shape[0] == user_anno.shape[1]\n",
    "                \n",
    "                \n",
    "                D = []\n",
    "                D = [rc_func(probs, x)[0] for x in user_anno]\n",
    "                t = np.mean(D)\n",
    "                \n",
    "                if t > Best_score:\n",
    "                    Best_score = t\n",
    "\n",
    "                global_policy_prob = F.softmax(global_policy, dim = 1)\n",
    "                global_policy_action = global_policy_prob.max(1, keepdim = True)[1].data.cpu().numpy()[:, 0]\n",
    "\n",
    "\n",
    "                update_idx = idx\n",
    "                local_abnormal_done = torch.ones(BATCH_SIZE)\n",
    "\n",
    "                for i in range(BATCH_SIZE):\n",
    "\n",
    "                    for local_id in range(Local_Seq_Len):\n",
    "                        if global_policy_action[i] == local_id:      #表示对第几帧进行操作\n",
    "                            move_policy_prob = F.softmax(move_policy[i], dim = 0)\n",
    "                            move_policy_action = move_policy_prob.max(0, keepdim=True)[1].data.cpu().numpy()\n",
    "\n",
    "                            if move_policy_action == 0:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_left_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 1:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_right_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 2:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_left_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 3:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_right_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            else:\n",
    "                                local_abnormal_done[i] = 0\n",
    "                \n",
    "                currrent_feature_1 = seq[update_idx[0]]\n",
    "                currrent_feature_2 = seq[update_idx[1]]\n",
    "                currrent_feature_3 = seq[update_idx[2]]\n",
    "                currrent_feature_4 = seq[update_idx[3]]\n",
    "                currrent_feature_5 = seq[update_idx[4]]\n",
    "                currrent_feature_6 = seq[update_idx[5]]\n",
    "                currrent_feature_7 = seq[update_idx[6]]\n",
    "                currrent_feature_8 = seq[update_idx[7]]\n",
    "                currrent_feature_9 = seq[update_idx[8]]\n",
    "                currrent_feature_10 = seq[update_idx[9]]\n",
    "                current_feature_concate = torch.from_numpy(np.concatenate([currrent_feature_1, currrent_feature_2, currrent_feature_3, currrent_feature_4, currrent_feature_5, \\\n",
    "                                                          currrent_feature_6, currrent_feature_7, currrent_feature_8, currrent_feature_9, currrent_feature_10], axis=0)).unsqueeze(0)\n",
    "                      \n",
    "            \n",
    "            score_list.append(Best_score)\n",
    "        print(np.mean(score_list))\n",
    "    user_anno_datasets.close()\n",
    "    dataset.close()\n",
    "    model.train()\n",
    "    return np.mean(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = PRL_VS()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "model_save_path = os.path.join('./resualt/best_resualt/summe/model_epoch4_0.454531550077155_summe.pth.tar')\n",
    "print(\"Loading checkpoint from '{}'\".format(model_save_path))\n",
    "checkpoint = torch.load(model_save_path, map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "metric = 'kendalltau'#'spearmanr' or 'kendalltau'\n",
    "score = new_evaluate_metric(model, use_gpu, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = h5py.File('./datasets/summe_user_anno.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rc_func(metric):\n",
    "    if metric == 'kendalltau':\n",
    "        f = lambda x, y: kendalltau(rankdata(-x), rankdata(-y))\n",
    "    elif metric == 'spearmanr':\n",
    "        f = lambda x, y: spearmanr(x, y)\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "    return f\n",
    "\n",
    "class RankCorrelationEvaluator(object):\n",
    "    \n",
    "    def __call__(self):\n",
    "        res = []\n",
    "        for d in data:\n",
    "            user_anno = data[d]['user_anno'][...]\n",
    "            N = user_anno.shape[1]\n",
    "\n",
    "            D = []\n",
    "            mean_tau = []\n",
    "            min_tau = []\n",
    "            max_tau = []\n",
    "\n",
    "            pred_x = self.get_score(d)\n",
    "            D = [self.rc_func(x, pred_x)[0] for x in user_anno]\n",
    "\n",
    "            res.append({'video': d,\n",
    "                        'mean': np.mean(D),\n",
    "                       'min': np.min(D), \n",
    "                       'max': np.max(D), \n",
    "                        'cc': np.asarray(D)\n",
    "                       })\n",
    "        return res\n",
    "\n",
    "class HumanEvaluator(RankCorrelationEvaluator):\n",
    "    def __init__(self, metric):\n",
    "        self.rc_func = get_rc_func(metric)\n",
    "    \n",
    "    def __call__(self):\n",
    "        res = []\n",
    "        for d in data:\n",
    "            user_anno = data[d]['user_anno'][...]\n",
    "            N = user_anno.shape[1]\n",
    "            \n",
    "            max_rc = []\n",
    "            min_rc = []\n",
    "            avr_rc = []\n",
    "            rc = []\n",
    "            for i, x in enumerate(user_anno):\n",
    "                R = [self.rc_func(x, user_anno[j])[0] for j in range(len(user_anno)) if j != i]\n",
    "                \n",
    "                max_rc.append(max(R))\n",
    "                min_rc.append(min(R))\n",
    "                avr_rc.append(np.mean(R))\n",
    "                rc += R\n",
    "                \n",
    "            res.append({'video': d,\n",
    "                        'mean': np.mean(avr_rc),\n",
    "                       'min': np.mean(min_rc), \n",
    "                       'max': np.mean(max_rc), \n",
    "                        'cc': np.asarray(rc)\n",
    "                       })\n",
    "        return res\n",
    "    \n",
    "class RandomEvaluator(RankCorrelationEvaluator):\n",
    "    def __init__(self, metric):\n",
    "        self.rc_func = get_rc_func(metric)\n",
    "        \n",
    "        rand_scores = {}\n",
    "        for d in data:\n",
    "            user_anno = data[d]['user_anno'][...]\n",
    "            N = user_anno.shape[1]\n",
    "            rand_scores[d] = np.random.random((N,))\n",
    "            \n",
    "        self.rand_scores = rand_scores\n",
    "            \n",
    "    def get_score(self, v_id):\n",
    "        return self.rand_scores[v_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric = 'spearmanr'\n",
    "human_res = HumanEvaluator(metric)()\n",
    "mean_arr = np.asarray([x['mean'] for x in human_res])\n",
    "print('human'+': mean %.3f'%(np.mean(mean_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric = 'kendalltau'\n",
    "human_res = HumanEvaluator(metric)()\n",
    "mean_arr = np.asarray([x['mean'] for x in human_res])\n",
    "print('human'+': mean %.3f'%(np.mean(mean_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance score correlations visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 生成模型的pred文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pred(model, use_gpu):\n",
    "    print(\"===> generate pred h5 file\")\n",
    "    dataset = h5py.File(DATASET, 'r')\n",
    "    vlist = []\n",
    "    for key in dataset.keys():\n",
    "        vlist.append(key)\n",
    "    \n",
    "    h5_file = h5py.File('./datasets/summe_pred_47.35.h5', 'w')\n",
    "    \n",
    "    for idx in range(50):\n",
    "        h5_file.create_group('video_{}'.format(idx+1))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        if use_gpu: model = model.cuda()\n",
    "        fms = []\n",
    "        eval_metric = 'avg' if METRIC == 'tvsum' else 'max'\n",
    "        \n",
    "        test_dataset = Charades_dataset(vlist)\n",
    "        testloader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0)\n",
    "        \n",
    "        for batch_idx, key in enumerate(testloader):\n",
    "            seq = dataset[key[0]]['features'][...]\n",
    "            seq_furtrue = torch.from_numpy(seq).unsqueeze(0) \n",
    "            global_feature_concate, idx, idx_list, five_unit, num_units = inital_data_process(seq)#[1024]\n",
    "            global_feature_concate = torch.from_numpy(global_feature_concate).unsqueeze(0)        #[batch_size,1024]\n",
    "            hidden_state = torch.zeros(BATCH_SIZE, Visual_Feature_Dim)\n",
    "            current_feature_concate = global_feature_concate\n",
    "            BEST_F_score = 0.0\n",
    "\n",
    "            for step in range(NUM_STEPS):\n",
    "                if use_gpu: \n",
    "                    hidden_state = hidden_state.cuda()\n",
    "                    current_feature_concate = current_feature_concate.cuda()\n",
    "                    global_feature_concate = global_feature_concate.cuda()\n",
    "                    seq_furtrue = seq_furtrue.cuda()\n",
    "\n",
    "                hidden_state, global_policy, move_policy, iou_out2 = model(seq_furtrue, global_feature_concate, current_feature_concate, hidden_state)\n",
    "\n",
    "\n",
    "                probs = iou_out2.data.cpu().squeeze().numpy()\n",
    "                cps = dataset[key[0]]['change_points'][...]\n",
    "                num_frames = dataset[key[0]]['n_frames'][()]\n",
    "                nfps = dataset[key[0]]['n_frame_per_seg'][...].tolist()\n",
    "                positions = dataset[key[0]]['picks'][...]\n",
    "                user_summary = dataset[key[0]]['user_summary'][...]\n",
    "\n",
    "                machine_summary = generate_summary(probs, cps, num_frames, nfps, positions)\n",
    "                fm, _, _ = evaluate_summary(machine_summary, user_summary, eval_metric)\n",
    "\n",
    "                if fm > BEST_F_score:\n",
    "                    BEST_F_score = fm\n",
    "                    h5_file[key[0]]['probs'] = probs\n",
    "                    \n",
    "\n",
    "                global_policy_prob = F.softmax(global_policy, dim = 1)\n",
    "                global_policy_action = global_policy_prob.max(1, keepdim = True)[1].data.cpu().numpy()[:, 0]\n",
    "\n",
    "\n",
    "                update_idx = idx\n",
    "                local_abnormal_done = torch.ones(BATCH_SIZE)\n",
    "\n",
    "                for i in range(BATCH_SIZE):\n",
    "\n",
    "                    for local_id in range(Local_Seq_Len):\n",
    "                        if global_policy_action[i] == local_id:      #表示对第几帧进行操作\n",
    "                            move_policy_prob = F.softmax(move_policy[i], dim = 0)\n",
    "                            move_policy_action = move_policy_prob.max(0, keepdim=True)[1].data.cpu().numpy()\n",
    "\n",
    "                            if move_policy_action == 0:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_left_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 1:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_right_move_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 2:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_left_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            elif move_policy_action == 3:\n",
    "                                update_idx, _, _, local_abnormal_done[i] = determine_right_offset_range(idx, local_id, idx[local_id], five_unit, num_units)\n",
    "                            else:\n",
    "                                local_abnormal_done[i] = 0\n",
    "                \n",
    "                currrent_feature_1 = seq[update_idx[0]]\n",
    "                currrent_feature_2 = seq[update_idx[1]]\n",
    "                currrent_feature_3 = seq[update_idx[2]]\n",
    "                currrent_feature_4 = seq[update_idx[3]]\n",
    "                currrent_feature_5 = seq[update_idx[4]]\n",
    "                currrent_feature_6 = seq[update_idx[5]]\n",
    "                currrent_feature_7 = seq[update_idx[6]]\n",
    "                currrent_feature_8 = seq[update_idx[7]]\n",
    "                currrent_feature_9 = seq[update_idx[8]]\n",
    "                currrent_feature_10 = seq[update_idx[9]]\n",
    "                current_feature_concate = torch.from_numpy(np.concatenate([currrent_feature_1, currrent_feature_2, currrent_feature_3, currrent_feature_4, currrent_feature_5, \\\n",
    "                                                          currrent_feature_6, currrent_feature_7, currrent_feature_8, currrent_feature_9, currrent_feature_10], axis=0)).unsqueeze(0)\n",
    "                      \n",
    "            \n",
    "    h5_file.close()\n",
    "    dataset.close()\n",
    "    model.train()\n",
    "    print(\"pred h5 file is finished\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = PRL_VS()\n",
    "# use_gpu = torch.cuda.is_available()\n",
    "# model_save_path = os.path.join('./resualt/best_resualt/summe/model_epoch19_0.47265147229948906_summe.pth.tar')\n",
    "# print(\"Loading checkpoint from '{}'\".format(model_save_path))\n",
    "# checkpoint = torch.load(model_save_path, map_location = 'cpu')\n",
    "# model.load_state_dict(checkpoint)\n",
    "# generate_pred(model, use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accum_eval(pred, gt):\n",
    "    total = gt.mean(axis=0).sum()\n",
    "    x = np.argsort(pred)[::-1]\n",
    "    y = [0]\n",
    "    for i in range(x.size):\n",
    "        cur_score = y[-1]\n",
    "        y.append(cur_score + gt[:, x[i]].mean())\n",
    "    y = np.asarray(y[1:]) / total\n",
    "    return y\n",
    "\n",
    "def best_curve(gt):\n",
    "    total = gt.mean(axis=0).sum()\n",
    "    x = np.argsort(gt.mean(axis=0))[::-1]\n",
    "    \n",
    "    y = [0]\n",
    "    for i in range(x.size):\n",
    "        cur_score = y[-1]\n",
    "        y.append(cur_score + gt[:, x[i]].mean())\n",
    "\n",
    "    y = np.asarray(y[1:]) / total\n",
    "    \n",
    "    return y\n",
    "\n",
    "def worst_curve(gt):\n",
    "    total = gt.mean(axis=0).sum()\n",
    "    x = np.argsort(gt.mean(axis=0))\n",
    "    \n",
    "    y = [0]\n",
    "    for i in range(x.size):\n",
    "        cur_score = y[-1]\n",
    "        y.append(cur_score + gt[:, x[i]].mean())\n",
    "    y = np.asarray(y[1:]) / total\n",
    "    return y\n",
    "\n",
    "def plot_user_scores(user_anno):\n",
    "    user_anno = (user_anno - 0)/18.\n",
    "    N = len(user_anno)\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "\n",
    "    # upper-bound\n",
    "    best_y = best_curve(user_anno)\n",
    "    best_auc = auc(np.linspace(0, 1, best_y.size), best_y)\n",
    "\n",
    "    # lower-bound\n",
    "    worst_y = worst_curve(user_anno)\n",
    "    worst_auc = auc(np.linspace(0, 1, worst_y.size), worst_y)\n",
    "\n",
    "    plt.fill_between(range(len(best_y)), worst_y, best_y, color='lightblue', alpha=.5)\n",
    "\n",
    "    mean_auc = 0\n",
    "    for i in range(N):\n",
    "        pred = user_anno[i]\n",
    "        y = accum_eval(pred, user_anno[list(range(i))+list(range(i+1, N))])\n",
    "        mean_auc += auc(np.linspace(0, 1, y.size), y)\n",
    "        p0 = plt.plot(y, color='lightcoral', alpha=.5)\n",
    "        \n",
    "    return mean_auc, best_auc, worst_auc, p0\n",
    "\n",
    "def plot_curve_rlvsumm():\n",
    "    tvsum_data = h5py.File('./datasets/summe_user_anno.h5', 'r')\n",
    "    pred_h5 = h5py.File('./datasets/summe_pred_47.35.h5', 'r')\n",
    "\n",
    "    human_auc_summary = []\n",
    "    random_auc_summary = []\n",
    "    model_auc_summary = []\n",
    "    rel_human_auc = []\n",
    "    rel_random_auc = []\n",
    "    rel_model_auc = []\n",
    "    \n",
    "    \n",
    "    for gt in tvsum_data:\n",
    "        user_anno = tvsum_data[gt]['user_anno'][...]\n",
    "        n_fr = user_anno.shape[1]\n",
    "        N = len(user_anno)\n",
    "\n",
    "        human_mean_auc, best_auc, worst_auc, p0 = plot_user_scores(user_anno)\n",
    "        human_auc_summary.append(human_mean_auc / N)\n",
    "        rel_human_auc.append((human_auc_summary[-1]-worst_auc) / (best_auc-worst_auc)*100)\n",
    "\n",
    "        # plot curve by random scoring\n",
    "        pred = np.random.random((n_fr))\n",
    "        y = accum_eval(pred, user_anno)\n",
    "        p1 = plt.plot(y, color='k', linestyle='--')\n",
    "        random_auc = auc(np.linspace(0, 1, y.size), y)\n",
    "        random_auc_summary.append(random_auc)\n",
    "        rel_random_auc.append((random_auc-worst_auc) / (best_auc-worst_auc)*100)\n",
    "        \n",
    "        assert len(pred) == user_anno.shape[1]\n",
    "        pred = pred_h5[gt]['probs'][...]\n",
    "        y = accum_eval(pred, user_anno)\n",
    "        p2 = plt.plot(y, color='royalblue', linestyle='--')\n",
    "        model_auc = auc(np.linspace(0, 1, y.size), y)\n",
    "        model_auc_summary.append(model_auc)\n",
    "        rel_model_auc.append((model_auc-worst_auc) / (best_auc-worst_auc)*100)\n",
    "\n",
    "        \n",
    "        plt.legend((p0[0], p1[0], p2[0]), ('Humans', 'Random', 'model'))\n",
    "        plt.title(gt)\n",
    "        plt.savefig('./imgs/summe/' + gt +'.png')\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "    \n",
    "    tvsum_data.close()\n",
    "    pred_h5.close()\n",
    "    print('random:', sum(random_auc_summary)/len(random_auc_summary), sum(rel_random_auc)/len(rel_random_auc), '\\n',\n",
    "         'human:', sum(human_auc_summary)/len(human_auc_summary), sum(rel_human_auc)/len(rel_human_auc),'\\n',\n",
    "         'model',sum(model_auc_summary)/len(model_auc_summary), sum(rel_model_auc)/len(rel_model_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context('notebook', font_scale=1.3)\n",
    "plot_curve_rlvsumm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
